# ğŸ¾ FPGA vs CPU Inference â€” Visual Comparison Report

**Image:** `test1dog.jpg` &nbsp;|&nbsp; **Subject:** Black German Shepherd  
**Platform:** Zynq-7020 PYNQ Board &nbsp;|&nbsp; **Weights:** FPGA Weights A

---

## ğŸ–¼ï¸ Output Images

### ğŸ† FPGA Inference Output â€” CORRECT âœ…
<img width="1426" height="728" alt="image" src="https://github.com/user-attachments/assets/08317ea3-1720-4e46-878e-acf28b108def" />

> FPGA classifies as **Dog âœ… CORRECT** â€” 150ms / 6.7 FPS

---

### CPU Inference Output â€” WRONG âŒ
<img width="1426" height="728" alt="image" src="https://github.com/user-attachments/assets/9d5c7393-0287-40d9-8c40-1259aa3c6813" />

> CPU classifies as **Cat âŒ WRONG** â€” 14.3ms / 69.8 FPS â€” 100% confidently incorrect

---

## ğŸ“Š Side-by-Side Results

| Metric | ğŸ† FPGA (Weights A) | CPU (NumPy) |
|---|---|---|
| **Prediction** | âœ… **Dog â€” CORRECT** | âŒ Cat â€” WRONG |
| **Ground Truth** | ğŸ• Dog | ğŸ• Dog |
| **Confidence** | 55% | 100% (wrong) |
| **Latency** | 150 ms | 14.3 ms |
| **Throughput** | 6.7 FPS | 69.8 FPS |
| **Margin** | 8M | 1.0000 |
| **Result** | ğŸ† **WINS** | âŒ Loses |

---

## ğŸ§  The Key Lesson â€” Speed â‰  Accuracy

The CPU is **6.6Ã— faster** and **100% confident** â€” and completely wrong.

The FPGA is slower and only 55% confident â€” and **got the right answer**.

```
Ground Truth:  ğŸ• DOG

FPGA   â†’  Dog  âœ…  150ms   55% conf   â† CORRECT
CPU    â†’  Cat  âŒ   14ms  100% conf   â† WRONG, confidently
```

> **High confidence does not mean correct.** It means the model strongly committed to a decision. In this case the CPU committed hard to the wrong class.

---

## ğŸ” Why Did the CPU Get It Wrong?

The CPU forward pass uses **float32 weights** â€” higher numerical precision than the FPGA's INT8. But more precision doesn't mean better generalization.

The float32 model likely **overfit** to specific texture/edge features in training that associate pointed ears and dark fur with cats. When it sees this black German Shepherd at 64Ã—64 grayscale resolution, those same features fire strongly â€” and the model confidently outputs Cat.

The FPGA's **INT8 quantization** acts like slight regularization â€” the rounding of weight values smooths out some of the overfitting, and in this case that actually helped the model generalize correctly to the dog.

```
Float32 precision  â†’  memorizes fine-grained patterns  â†’  overfits  â†’  Cat âŒ
INT8 quantization  â†’  slightly smoothed weights         â†’  generalizes â†’  Dog âœ…
```

This is a real-world example of why quantized models sometimes **outperform** their float32 counterparts on out-of-distribution or edge-case images.

---

## âš¡ Full Comparison

```
Accuracy (what matters most):
  FPGA  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  CORRECT âœ…
  CPU   â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  WRONG   âŒ

Latency (lower = better):
  FPGA  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  150ms
  CPU   â–ˆâ–ˆâ–ˆâ–ˆ  14.3ms

FPS (higher = better):
  FPGA  â–ˆâ–ˆ  6.7 fps
  CPU   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  69.8 fps

Confidence:
  FPGA  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  55%  (uncertain but RIGHT)
  CPU   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  100% (certain but WRONG)
```

---

## âœ… Final Verdict

| Dimension | Winner | Notes |
|---|---|---|
| **Correct Classification** | ğŸ† **FPGA** | Dog âœ… vs Cat âŒ â€” only one that matters |
| Speed | CPU | 14.3ms vs 150ms |
| Power efficiency | ğŸ† **FPGA** | ~2.5W total PL+PS |
| Confidence calibration | ğŸ† **FPGA** | 55% uncertain = honest. 100% wrong = dangerous |
| Production reliability | ğŸ† **FPGA** | A wrong confident answer is worse than a correct uncertain one |

> ğŸ’¡ **Bottom line:** A fast wrong answer is useless. The FPGA delivered the right answer. In any real deployment â€” medical imaging, autonomous systems, quality control â€” correctness beats speed every time.

---

## ğŸ› ï¸ Next Steps to Fix CPU

The CPU model needs retraining or recalibration to match the FPGA's correctness on this class of image:

- **Augment training data** with more dark-furred dogs at low resolution
- **Add dropout** to reduce overconfidence on ambiguous inputs
- **Quantization-aware training (QAT)** â€” train with INT8 simulation so both models agree
- **Temperature scaling** â€” calibrate softmax outputs so 100% confidence is never assigned to borderline inputs

---

*Report generated from PYNQ inference run on `test1dog.jpg` â€” Vivado 2023.1 / PYNQ v2.7*  
*Ground truth: ğŸ• Dog â€” FPGA correct, CPU incorrect*
